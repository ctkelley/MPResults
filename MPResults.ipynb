{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\calf}{{\\cal F}}\n",
    "\\newcommand{\\dnu}{d \\nu}\n",
    "\\newcommand{\\mf}{{\\bf F}}\n",
    "\\newcommand{\\vu}{{\\bf u}}\n",
    "\\newcommand{\\ve}{{\\bf e}}\n",
    "\\newcommand{\\mg}{{\\bf G}}\n",
    "\\newcommand{\\ml}{{\\bf L}}\n",
    "\\newcommand{\\mg}{{\\bf G}}\n",
    "\\newcommand{\\mi}{{\\bf I}}\n",
    "\\newcommand{\\diag}{\\mbox{diag}}\n",
    "\\newcommand{\\begeq}{{\\begin{equation}}}\n",
    "\\newcommand{\\endeq}{{\\end{equation}}}\n",
    "$\n",
    "\n",
    "\n",
    "# Newton's Method in Multiple Precision: C. T. Kelley\n",
    "\n",
    "This notebook documents the results in \n",
    " <cite data-cite=\"ctk:sirev20\"><a href=\"newtonmp.html#ctk:sirev20\">(Kel20)</cite><br>\n",
    "    \n",
    "C. T. Kelley, ***Newton's Method in Mixed Precision***, 2020    \n",
    "\n",
    "As an example we will solve the Chandrasekhar H-equation <cite data-cite=\"chand\"><a href=\"newtonmp.html#chand\">(Cha60)</cite>. This equation, which we describe in detail in the Example section, has a fast $O(N \\log(N))$ function evaluation, a Jacobian evaluation that is $O(N^2)$ work analytically and $O(N^2 \\log(N))$ with a finite difference. This means that most of the work, if you do things right, is in the LU factorization of the Jacobian. \n",
    "    \n",
    "The difference between double, single, and half precision will be clear in the results from the examples.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Example: The Chandrasekhar H-Equation](#The-Chandrasekhar-H-Equation)\n",
    "\n",
    "- [Setting up the notebook](#Setting-up): Install the application.\n",
    "\n",
    "- [First run of the solver](#Running-the-solver)\n",
    "\n",
    "- [How to use the solver](#KNL)\n",
    "\n",
    "- [The results in the paper](#The-results-in-the-paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Chandrasekhar H-Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "The example is the mid-point rule discretization of the Chandrasekhar H-equation <cite data-cite=\"chand\"><a href=\"newtonmp.html#chand\">(Cha60)</cite>.\n",
    "    \n",
    "    \n",
    " \n",
    "   \\begin{equation}\n",
    "    {\\calf}(H)(\\mu) = H(\\mu) -\n",
    "\\left(\n",
    "1 - \\frac{c}{2} \\int_0^1 \\frac{\\mu H(\\mu)}{\\mu + \\nu} \\dnu\n",
    "\\right)^{-1} = 0.\n",
    "    \\end{equation}\n",
    "    \n",
    "    \n",
    "The nonlinear operator $\\calf$ is defined on $C[0,1]$, the space of\n",
    "continuous functions on $[0,1]$.  \n",
    "\n",
    "The equation has a well-understood dependence on the parameter $c$\n",
    "<cite data-cite=\"twm68\"><a href=\"newtonmp.html#twm68\">(Mul68)</cite>,\n",
    "    <cite data-cite=\"ctk:n1\"><a href=\"newtonmp.html#ctk:n1\">(DK80)</cite>.\n",
    "The equation has unique solutions at $c=0$\n",
    "and $c=1$ and two solutions for $0 < c < 1$. There is a simple fold\n",
    "singularity \n",
    "        <cite data-cite=\"herb\"><a href=\"newtonmp.html#herb\">(Kel87)</cite>\n",
    "        at $c=1$. Only one \n",
    "        <cite data-cite=\"chand\"><a href=\"newtonmp.html#chand\">(Cha60)</cite>,\n",
    "        <cite data-cite=\"busb\"><a href=\"newtonmp.html#busb\">(Bus60)</cite>\n",
    "            of the two solutions for $0 < c < 1$ is of physical interest\n",
    "and that is the one easiest to find numerically. One must do\n",
    "a continuation computation to find the other one.\n",
    "\n",
    "The structure of the singularity is preserved if one discretizes\n",
    "the integral with any rule that integrates constants exactly. For\n",
    "the purposes of this paper the composite midpoint rule will suffice.\n",
    "The $N$-point composite midpoint rule is\n",
    "\\begin{equation}\n",
    "\\int_0^1 f(\\nu) \\dnu \\approx \\frac{1}{N} \\sum_{j=1}^N f(\\nu_j)\n",
    "\\end{equation}\n",
    "where $\\nu_j = (j - 1/2)/N$ for $1 \\le j \\le N$. This rule is\n",
    "second-order accurate for sufficiently smooth functions $f$. The\n",
    "solution of the integral equation is, however, not smooth enough. $H'(\\mu)$\n",
    "has a logarithmic singularity at $\\mu=0$.\n",
    "\n",
    "The discrete problem is\n",
    "\n",
    "\\begin{equation}\n",
    "\\mf(\\vu)_i \\equiv\n",
    "u_i - \\left(\n",
    "1  - \\frac{c}{2N} \\sum_{j=1}^N \\frac{u_j \\mu_i}{\\mu_j + \\mu_i}\n",
    "\\right)^{-1}\n",
    "=0.\n",
    "\\end{equation}\n",
    "\n",
    "One can simplify the approximate integral operator in \\eqnok{hmid}\n",
    "and expose some useful structure. Since\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{c}{2N} \\sum_{j=1}^N \\frac{u_j \\mu_i}{\\mu_j + \\mu_i}\n",
    "= \\frac{c (i - 1/2) }{2N} \\sum_{j=1}^N \\frac{u_j}{i+j -1}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "hence the approximate integral operator is\n",
    "the product of a diagonal matrix and a Hankel matrix and\n",
    "one can use an FFT to evaluate that operator with $O(N \\log(N))$\n",
    "work \n",
    "<cite data-cite=\"golub\"><a href=\"newtonmp.html#golub\">(GV96)</cite>.\n",
    "    \n",
    "We can express the approximation of the integral operator in matrix\n",
    "form\n",
    "\\begin{equation}\n",
    "\\ml(\\vu)_i = \\frac{c (i - 1/2) }{2N} \\sum_{j=1}^N \\frac{u_j}{i+j -1}\n",
    "\\end{equation}\n",
    "and compute the Jacobian analytically as\n",
    "\\begin{equation}\n",
    "\\mf'(\\vu) = \\mi - \\diag(\\mg(\\vu))^2 \\ml\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "\\mg(\\vu)_i = \\left(\n",
    "1  - \\frac{c}{2N} \\sum_{j=1}^N \\frac{u_j \\mu_i}{\\mu_j + \\mu_i}\n",
    "\\right)^{-1}.\n",
    "\\end{equation}\n",
    "Hence the data for the Jacobian is already available after\n",
    "one computes $\\mf(\\vu) = \\vu - \\mg(\\vu)$ and the Jacobian can\n",
    "be computed with $O(N^2)$ work.\n",
    "We do that in this example and therefore the only $O(N^3)$\n",
    "part of the solve is the matrix factorization.\n",
    "\n",
    "One could also approximate the Jacobian with forward differences.\n",
    "In this case one approximates the $j$th column $\\mf'(\\vu)_j$\n",
    "of the Jacobian with\n",
    "\\begin{equation}\n",
    "\\frac{\\mf(\\vu + h {\\tilde \\ve}_j) - \\mf(\\vu)}{h}\n",
    "\\end{equation}\n",
    "where ${\\tilde \\ve}_j$ is a unit vector in the $j$th coordinate\n",
    "direction and $h$ is a suitable difference increment. If one computes\n",
    "$\\mf$ in double precision with unit roundoff $u_d$, then\n",
    "$h =O(\\| \\vu \\| \\sqrt{u_d})$ is a reasonable choice \n",
    "<cite data-cite=\"ctk:roots\"><a href=\"newtonmp.html#ctk:roots\">(Kel95)</cite>.\n",
    "Then\n",
    "the error in the Jacobian is $O(\\sqrt{u_d}) = O(u_s)$ where $u_s$ is\n",
    "unit roundoff in single precision. The cost of a finite difference Jacobian\n",
    "in this example is $O(N^2 \\log(N))$ work.\n",
    "\n",
    "The analysis in  <cite data-cite=\"ctk:sirev19\"><a href=\"newtonmp.html#ctk:sirev19\">(Kel19)</cite> suggests that there\n",
    "is no significant difference in the nonlinear iteration\n",
    "from either the choice of analytic or finite difference Jacobians\n",
    "or the choice of single or double precision for the linear solver. This notebook has the data used in that paper\n",
    "to support that assertion. You will be able to duplicate the results and play with the codes.\n",
    "    \n",
    "Half precision is another story and we have those codes for you, too.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You need to install these packages:\n",
    "\n",
    "- PyPlot\n",
    "- LinearAlgebra\n",
    "- JLD2\n",
    "- Printf\n",
    "- FFTW\n",
    "- IJulia (You must have done this already or you would not be looking at this notebook.)\n",
    "- AbstractFFTs\n",
    "\n",
    "The directory is a Julia project. So all you should need to do to get going is to\n",
    "\n",
    "1. Put the directory in your LOAD_PATH. The way to do this is to type\n",
    "```Julia\n",
    "push!(LOAD_PATH,\"/Users/yourid/whereyouputit/MPResults2019\")\n",
    "```\n",
    "at the Julia prompt in the REPL or in a notebook code windown.\n",
    "\n",
    "2. Now load the modules with\n",
    "```Julia\n",
    "using MPResults2019\n",
    "```\n",
    "\n",
    "3. Then you can do a simple solve and test that you did it right by typing\n",
    "```Julia\n",
    "hout=heqtest()\n",
    "```\n",
    "which I will do now. Make sure __MPResults__ is in your LOAD_PATH! If you forget to do the push! command, strange things may happen.\n",
    "\n",
    "Make absolutely sure that you are in the MPResults directory. Then ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package MPResults [aecca6c3-dca7-5716-8494-c57fe5e8d3bf] is required but does not seem to be installed:\n - Run `Pkg.instantiate()` to install all recorded dependencies.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package MPResults [aecca6c3-dca7-5716-8494-c57fe5e8d3bf] is required but does not seem to be installed:\n - Run `Pkg.instantiate()` to install all recorded dependencies.\n",
      "",
      "Stacktrace:",
      " [1] _require(::Base.PkgId) at ./loading.jl:998",
      " [2] require(::Base.PkgId) at ./loading.jl:927",
      " [3] require(::Module, ::Symbol) at ./loading.jl:922",
      " [4] top-level scope at In[16]:6"
     ]
    }
   ],
   "source": [
    "\n",
    "cd(\"/Users/ctk/Dropbox/Julia/dev/MPResults\")\n",
    "pwd()\n",
    "MPRdir=pwd()\n",
    "push!(LOAD_PATH,MPRdir)\n",
    "using MPResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes solve the H-equation and plot/tabulate the results in various ways. __heqtest__ prints on column of the tables in Chandrasekhar's book. It calls __knl.jl__ . I've shown you the output from the solver but that is not important for now. You get the details on the solver in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: heqtest not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: heqtest not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[5]:1"
     ]
    }
   ],
   "source": [
    "heqtest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heqtest.jl, calls the solver and harvests some iteration statistics. The two columns of numbers are the reults from <cite data-cite=\"chand\"><a href=\"newtonmp.html#chand\">(Cha60)</cite> (page 125). The iteration statistics are from KNL, the solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  KNL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The solver is _knl.jl_ version .01. Keep in mind that nothing with a version number with a negative exponent field is likely to be very good. knl.jl is included when you run the MPResults2019.jl module, which you do automatically when you type __using MPResults2019__\n",
    "\n",
    "\n",
    "knl.jl is a simple implemention of Newton's method (see \n",
    "<cite data-cite=\"ctk:roots\"><a href=\"newtonmp.html#ctk:roots\">(Kel95)</cite> and\n",
    "<cite data-cite=\"ctk:newton\"><a href=\"newtonmp.html#ctk:newton\">(Kel03)</cite> )\n",
    "using an LU factorization of the Jacobian to compute the Newton step with no line search or globalization. The code evaluates and factors the Jacobian at every nonlinear iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using knl.jl ##\n",
    "\n",
    "At the level of this notebook, it's pretty simple. Remember that Julia hates to allocate mememory. So your function and Jacobian evaluation routines should expect the calling function to **preallocate** the storage for both the function and Jacobian. Your functions will then use __.=__ to put the function and Jacobian where they are supposed to be.\n",
    "\n",
    "It's worthwhile to look at the help screen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth asking for help with knl ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: install\u001b[0m\u001b[1mk\u001b[22mer\u001b[0m\u001b[1mn\u001b[22me\u001b[0m\u001b[1ml\u001b[22m\n",
      "\n",
      "Couldn't find \u001b[36mknl\u001b[39m\n",
      "Perhaps you meant kill, In, ans, nb, nnz, Inf, Val, all, any, in, inv or one\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\n",
       "Binding \\texttt{knl} does not exist.\n",
       "\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "Binding `knl` does not exist.\n"
      ],
      "text/plain": [
       "  No documentation found.\n",
       "\n",
       "  Binding \u001b[36mknl\u001b[39m does not exist."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?knl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How knl.jl controls the precision of the Jacobian##\n",
    "\n",
    "You can control the precision of the Jacobian by simply allocating FPS in your favorite precision. So if I have a problem with N=256 unknows I will decalare FP as zeros(N,1) and may delcare FPS as zeros(N,N) or Float32.(zeros(N,N)).\n",
    "\n",
    "Note the __.__ between Float32 and the paren. This, as is standard Julia practice, applies the conversion to Float32 to everyelement in the array. If you forget the __.__ Julia will complain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The results in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The paper has plots for double, single, and half precsion computations for c=.5, .99, and 1.0. The half precision results take a very long time to get. On my computer (2019 iMac; 8 cores, 64GB of memoroy) the half precision compute time was over two weeks. Kids, don't try this at home.\n",
    "\n",
    "The data for the paper are in the cleverly named directory __Data_From_Paper__\n",
    "\n",
    "__cd to the directory MPResults__ and __from that directory__ run\n",
    "\n",
    "```Julia\n",
    "data_harvest(\"Data_From_Paper/MP_Data_\") \n",
    "```\n",
    "\n",
    "at the julia prompt you will generate all the tables and plots in the paper.\n",
    "\n",
    "If you have the time and patience you can also generate the data with data_populate.jl. This create three directories named Mixed_Precision_c=? and you can see for yourself. Look at that file to see opportunities to edit the time-cosumng jobs out. If you eliminate the half precision work and the larger dimensions, the code will run in a short time. \n",
    "\n",
    "Here is a simple example of using data_populate and the plotter code plot_knl.jl. I'm only using the 1024, 2048 and 4096 point grids. The plot in the paper uses more levels. This is part of Figure 1 in the paper.\n",
    "\n",
    "Look at the source to __data_populate.jl__ and __plotknl.jl__ and you'll see how I did this. These codes only mange files, plots, and tables. There is nothing really exciting here. You don't need to know much Julia to understand this, but you do need to know something and I can't help with that.\n",
    "\n",
    "To begin with, I will create a directory called Data_Test to put all this stuff. I will cd to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/ctk/Dropbox/Julia/dev/MPResults/Data_Test/Data_Test\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Home4mp=\"Data_Test\"\n",
    "try (mkdir(Home4mp))\n",
    "catch\n",
    "end\n",
    "cd(Home4mp)\n",
    "pwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll run **data_populate** to create a subdirectory with the data. cd to that directory and run __plotknl__. That's how I created the plots in the paper with all values of *c* and all the problem sizes. The half precision computation took two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: data_populate not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: data_populate not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[10]:2"
     ]
    }
   ],
   "source": [
    "using PyPlot\n",
    "data_populate(.5;half=\"no\",level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Base.IOError",
     "evalue": "IOError: chdir Mixed_Precision_c=5: no such file or directory (ENOENT)",
     "output_type": "error",
     "traceback": [
      "IOError: chdir Mixed_Precision_c=5: no such file or directory (ENOENT)",
      "",
      "Stacktrace:",
      " [1] uv_error at ./libuv.jl:97 [inlined]",
      " [2] cd(::String) at ./file.jl:84",
      " [3] top-level scope at In[9]:1"
     ]
    }
   ],
   "source": [
    "cd(\"Mixed_Precision_c=5\")\n",
    "figtitle=\"Figure 1\"\n",
    "plotknl(\"no\",.5,10,3;bigtitle=figtitle)\n",
    "cd(\"..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__data_populate__ will create directories for your data if they are not already there. Run __plot_knl__ from one of those directories and it makes the plots. As you can see from the one above, it's hard to tell the difference between double and single precision linear algebra and analytic or finite difference Jacobians. You knew that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
